# Project Backlog

## BACKLOG

### Audio Processing

- [ ] ğŸ¯ Implement audio chunking with overlapping segments for seamless transcription
      â¤· _why_: Prevents word cutoffs at 10s boundaries
      â¤· _skill_: bash / ffmpeg

- [ ] ğŸ¯ Add audio quality validation and normalization pipeline
      â¤· _why_: Ensures consistent ASR performance across different input sources
      â¤· _skill_: python / audio-processing

- [ ] ğŸ¯ Support multiple audio formats (MP3, M4A, FLAC) with automatic conversion
      â¤· _why_: Broader compatibility with various debate recording formats
      â¤· _skill_: bash / ffmpeg

### ASR (Automatic Speech Recognition)

- [ ] ğŸ¯ Implement whisper.cpp subprocess integration with error handling
      â¤· _why_: Core transcription functionality for the pipeline
      â¤· _skill_: python / subprocess

- [ ] ğŸ¯ Add confidence scoring and retry logic for low-quality transcriptions
      â¤· _why_: Improves accuracy and handles audio quality variations
      â¤· _skill_: python / ml

- [ ] ğŸ¯ Optimize whisper model selection based on audio duration and quality
      â¤· _why_: Balance speed vs accuracy for different use cases
      â¤· _skill_: python / ml

### Speaker Diarization

- [ ] ğŸ¯ Integrate pyannote.audio with RTTM output parsing
      â¤· _why_: Essential for multi-speaker debate analysis
      â¤· _skill_: python / ml

- [ ] ğŸ¯ Implement speaker embedding clustering for consistent identity across chunks
      â¤· _why_: Maintains speaker consistency throughout long debates
      â¤· _skill_: python / ml

- [ ] ğŸ¯ Add speaker name assignment interface for known participants
      â¤· _why_: Enables personalized analytics and clearer visualization
      â¤· _skill_: python / frontend

### NLP & Stance Detection

- [ ] ğŸ¯ Build stance classification pipeline with sentence-transformers
      â¤· _why_: Core political position analysis functionality
      â¤· _skill_: python / ml

- [ ] ğŸ¯ Implement semantic caching for repeated phrases and common statements
      â¤· _why_: Significantly improves processing speed for live analysis
      â¤· _skill_: python / optimization

- [ ] ğŸ¯ Add sentiment analysis alongside stance detection
      â¤· _why_: Provides emotional context to supplement political positioning
      â¤· _skill_: python / ml

- [ ] ğŸ¯ Create topic modeling for automatic debate segment classification
      â¤· _why_: Enables topic-specific analytics and navigation
      â¤· _skill_: python / ml

### Data Pipeline & Orchestration

- [ ] ğŸ¯ Build JSON aggregation system merging ASR, diarization, and NLP outputs
      â¤· _why_: Creates unified data structure for dashboard consumption
      â¤· _skill_: python / data-engineering

- [ ] ğŸ¯ Implement incremental processing for real-time audio streams
      â¤· _why_: Enables live debate monitoring without full reprocessing
      â¤· _skill_: python / streaming

- [ ] ğŸ¯ Add data validation and error recovery mechanisms
      â¤· _why_: Ensures pipeline robustness during long debate sessions
      â¤· _skill_: python / reliability

### Dashboard & Visualization

- [ ] ğŸ¯ Create Streamlit dashboard with live transcript and stance gauges
      â¤· _why_: Primary user interface for debate monitoring
      â¤· _skill_: python / frontend

- [ ] ğŸ¯ Implement Plotly real-time gauges for stance tracking
      â¤· _why_: Visual representation of political positioning over time
      â¤· _skill_: python / visualization

- [ ] ğŸ¯ Add interactive timeline with clickable debate moments
      â¤· _why_: Enables quick navigation to key discussion points
      â¤· _skill_: python / frontend

- [ ] ğŸ¯ Build speaker analytics panel with talk time and interruption metrics
      â¤· _why_: Provides insights into debate dynamics and participation patterns
      â¤· _skill_: python / analytics

### DevX & Testing

- [ ] ğŸ¯ Create comprehensive requirements.txt with version pinning
      â¤· _why_: Ensures reproducible environment setup across different machines
      â¤· _skill_: python / devops

- [ ] ğŸ¯ Add unit tests for audio chunking and merging logic
      â¤· _why_: Prevents regressions in core processing pipeline
      â¤· _skill_: python / testing

- [ ] ğŸ¯ Create sample 30-second test audio with known ground truth
      â¤· _why_: Enables automated testing and performance benchmarking
      â¤· _skill_: audio-processing / testing

- [ ] ğŸ¯ Implement logging and monitoring for production readiness
      â¤· _why_: Essential for debugging and performance optimization
      â¤· _skill_: python / observability

## IN PROGRESS

### Foundation Setup

- [ ] ğŸ¯ Bootstrap project structure with proper directory organization
      â¤· _why_: Establishes clean architecture for development workflow
      â¤· _skill_: project-management

## BLOCKED / RISKS

### Model Dependencies

- [ ] âš ï¸ Whisper.cpp CoreML compilation may fail on older Xcode versions
      â¤· _risk_: Blocks ASR functionality entirely
      â¤· _mitigation_: Provide fallback to CPU-only whisper.cpp build

- [ ] âš ï¸ Pyannote.audio requires HuggingFace authentication token
      â¤· _risk_: Additional setup complexity for new users
      â¤· _mitigation_: Document token setup process clearly

### Performance Constraints

- [ ] âš ï¸ Real-time processing may exceed available compute on older MacBooks
      â¤· _risk_: Latency makes live monitoring impractical
      â¤· _mitigation_: Implement performance profiling and optimization guides

### Data Privacy

- [ ] âš ï¸ Local-only processing limits scalability but ensures privacy
      â¤· _risk_: Cannot handle large-scale deployment without cloud resources
      â¤· _mitigation_: Design modular architecture for optional cloud components
